\documentclass[11pt,preprint, authoryear]{elsarticle}

\usepackage{lmodern}
%%%% My spacing
\usepackage{setspace}
\setstretch{1.2}
\DeclareMathSizes{12}{14}{10}{10}

% Wrap around which gives all figures included the [H] command, or places it "here". This can be tedious to code in Rmarkdown.
\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

\let\origtable\table
\let\endorigtable\endtable
\renewenvironment{table}[1][2] {
    \expandafter\origtable\expandafter[H]
} {
    \endorigtable
}


\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi

\usepackage{amssymb, amsmath, amsthm, amsfonts}

\def\bibsection{\section*{References}} %%% Make "References" appear before bibliography


\usepackage[round]{natbib}

\usepackage{longtable}
\usepackage[margin=2.3cm,bottom=2cm,top=2.5cm, includefoot]{geometry}
\usepackage{fancyhdr}
\usepackage[bottom, hang, flushmargin]{footmisc}
\usepackage{graphicx}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\setlength{\parindent}{0cm}
\setlength{\parskip}{1.3ex plus 0.5ex minus 0.3ex}
\usepackage{textcomp}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.3pt}

\usepackage{array}
\newcolumntype{x}[1]{>{\centering\arraybackslash\hspace{0pt}}p{#1}}

%%%%  Remove the "preprint submitted to" part. Don't worry about this either, it just looks better without it:
\makeatletter
\def\ps@pprintTitle{%
  \let\@oddhead\@empty
  \let\@evenhead\@empty
  \let\@oddfoot\@empty
  \let\@evenfoot\@oddfoot
}
\makeatother

 \def\tightlist{} % This allows for subbullets!

\usepackage{hyperref}
\hypersetup{breaklinks=true,
            bookmarks=true,
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=blue,
            pdfborder={0 0 0}}


% The following packages allow huxtable to work:
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{calc}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{caption}


\newenvironment{columns}[1][]{}{}

\newenvironment{column}[1]{\begin{minipage}{#1}\ignorespaces}{%
\end{minipage}
\ifhmode\unskip\fi
\aftergroup\useignorespacesandallpars}

\def\useignorespacesandallpars#1\ignorespaces\fi{%
#1\fi\ignorespacesandallpars}

\makeatletter
\def\ignorespacesandallpars{%
  \@ifnextchar\par
    {\expandafter\ignorespacesandallpars\@gobble}%
    {}%
}
\makeatother

\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{CSLReferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}


\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

%%% Include extra packages specified by user

%%% Hard setting column skips for reports - this ensures greater consistency and control over the length settings in the document.
%% page layout
%% paragraphs
\setlength{\baselineskip}{12pt plus 0pt minus 0pt}
\setlength{\parskip}{12pt plus 0pt minus 0pt}
\setlength{\parindent}{0pt plus 0pt minus 0pt}
%% floats
\setlength{\floatsep}{12pt plus 0 pt minus 0pt}
\setlength{\textfloatsep}{20pt plus 0pt minus 0pt}
\setlength{\intextsep}{14pt plus 0pt minus 0pt}
\setlength{\dbltextfloatsep}{20pt plus 0pt minus 0pt}
\setlength{\dblfloatsep}{14pt plus 0pt minus 0pt}
%% maths
\setlength{\abovedisplayskip}{12pt plus 0pt minus 0pt}
\setlength{\belowdisplayskip}{12pt plus 0pt minus 0pt}
%% lists
\setlength{\topsep}{10pt plus 0pt minus 0pt}
\setlength{\partopsep}{3pt plus 0pt minus 0pt}
\setlength{\itemsep}{5pt plus 0pt minus 0pt}
\setlength{\labelsep}{8mm plus 0mm minus 0mm}
\setlength{\parsep}{\the\parskip}
\setlength{\listparindent}{\the\parindent}
%% verbatim
\setlength{\fboxsep}{5pt plus 0pt minus 0pt}



\begin{document}



\begin{frontmatter}  %

\title{Night Lights and Noisy Data - Using Machine Learning to Better
Detect Human-Generated Light}

% Set to FALSE if wanting to remove title (for submission)




\author[Add1]{Johannes Coetsee}
\ead{19491050@sun.ac.za}





\address[Add1]{Stellenbosch University}


\begin{abstract}
\small{
In recent years, researchers in the social sciences have increasingly
relied on the usage of alternative sources of data with which to answer
research questions. One of the avenues remote sensing data, and more
specifically, satellite data, as . One of the most prominent of these
datasets, the stable lights product from DMSP-OLS, has been especially
helpful. However, this product suffers from some potentially severe
accuracy-related problems. The following paper explicates on some of
these, and implements an adjusted version of the noise-filtering
methodology proposed by Määttä \& Lessmann
(\protect\hyperlink{ref-maatta}{2019}), in which the authors use a
variety of derived and externally sourced remote sensing inputs to
inform a Random Forest algorithm that categorises night-light data as
being human-generated. This methodology proves fruitful in preserving
data at the lower end of the light spectrum, which is often discarded
due to it being too noisy.
}
\end{abstract}

\vspace{1cm}

\begin{keyword}
\footnotesize{
Remote Sensing \sep Night Lights \sep Random Forest \\ \vspace{0.3cm}
}
\end{keyword}
\vspace{0.5cm}
\end{frontmatter}



%________________________
% Header and Footers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy}
\chead{}
\rhead{Advanced Cross Section - January 2022}
\lfoot{}
\rfoot{\footnotesize Page \thepage}
\lhead{}
%\rfoot{\footnotesize Page \thepage } % "e.g. Page 2"
\cfoot{}

%\setlength\headheight{30pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%________________________

\headsep 35pt % So that header does not go over title




\hypertarget{introduction}{%
\section{\texorpdfstring{Introduction
\label{Introduction}}{Introduction }}\label{introduction}}

The use of remote sensing data, and more specifically, satellite
nighttime light data, presents potential for new and diverse
applications in socioeconomic research. Nightlight data remains a
largely objective measure, and is thereby suitable to use as a proxy in
a broad array of studies that require the usage of potentially
unreliable or otherwise lacking data. This advantage is especially
pertinent in parts of the developing world, where socioeconomic research
can prove most beneficial. There exists different night lights products
which can be utilized towards this end, the most common of which is the
`Stable Lights' product, derived from the Defense Meteorological
Satellite Program's (DMSPs) Operational Linescan System (OLS). This
paper emphasises the usage of this product specifically focusing on its
shortcomings. Most prominently, DMSP-OLS has difficulty in separating
background noise from night lights generated from human-generated light,
especially in areas that display lower levels of night light intensity.
This presents an obvious problem: analyses that attempt to use Stable
Lights as a proxy for economic activity, for instance, would exaggerate
or understate economic activity in these low-luminous areas.

This paper attempts to address the challenge of inaccurate measurement
of night lights by applying a filtering technique to identify and
separate nightlights emitted by humans from those emitted by anything
else. This filtering process is based on the methodology for deriving
the `Local Human Lights' product by Määttä \& Lessmann
(\protect\hyperlink{ref-maatta}{2019}), and relies on a Random Forest
(RF) Machine Learning algorithm for classification.

\hypertarget{explication-of-the-problem}{%
\section{Explication of the Problem}\label{explication-of-the-problem}}

\hypertarget{stable-lights-and-economic-activity}{%
\subsection{Stable Lights and Economic
Activity}\label{stable-lights-and-economic-activity}}

The most prominent difficulty, however, relates to the amount of noise
in the lower end of the light distribution due in part to the blooming
effect mentioned above. Standard practice using the stable lights data
set is to discard these values from analysis, thereby removing a large
proportion of cell observations.

\hypertarget{method-and-data}{%
\section{\texorpdfstring{Method and Data
\label{Methodology}}{Method and Data }}\label{method-and-data}}

\begin{itemize}
\tightlist
\item
  Short overview of Määttä \& Lessmann
  (\protect\hyperlink{ref-maatta}{2019})
\end{itemize}

The filtering process used by Määttä \& Lessmann
(\protect\hyperlink{ref-maatta}{2019}) attempts to more accurately
detect specifically \emph{human-generated} night lights

\hypertarget{data}{%
\subsection{Data}\label{data}}

Table ref\{variables\_table\} below gives an overview of the most
important inputs

``- Global Human Settlement Layer (GHSL) built-up grid. It is based on
Landsat satellite images and prepared following the GHSL methodology

-The most important variables are the average visible band (avg\_light)
and frequency of light detection (freq\_light) images from NOAA. They
provide information on average light over one year and the percentage of
days with light detections in a pixel.

\begin{itemize}
\item
  In addition, we generate variables that describe light characteristics
  around a pixel. The regional input variables address concerns that the
  background noise in light data differs across regions. We use a
  local\_noise variable to identify regions, where the background noise
  in avg\_light is systematically higher. The variable counts the number
  of pixels below the value 6 in avg\_light image in a square window of
  499 × 499 pixels for all pixels.
\item
  For the Local Human Lights product, we add more variables on local
  light characteristics to maximize the classification accuracy. We
  create these variables by taking averages of avg\_light and
  freq\_light on different area sizes around a pixel. For example,
  lm\_avg\_199 calculates the average of avg\_light in a 199 × 199 pixel
  area around a pixel. Similarly, we create the variables lm\_freq\_5,
  lm\_avg\_25 and lm\_freq\_99. The reason for adding local averages on
  different area sizes is that we do not know the correct radius of
  spatial correlation in human-generated light. ''
\end{itemize}

\hypertarget{methodology}{%
\subsection{Methodology}\label{methodology}}

Maatta's methodology necessitates the following steps:

First, a host of regional night light variables are created from two of
the original DMSP-OLS products. These variables constitute some of the
most important inputs of the RF algorithm.

The second step in Määttä \& Lessmann
(\protect\hyperlink{ref-maatta}{2019})'s methodology is related to the
division of the world map in various sub-regions, with the algorithm

\begin{longtable}[]{@{}l@{}}
\toprule
\endhead
5. Local Human Lights Process \\
Our second product shifts weight from minimizing regional bias to
maximizing the accuracy in \\
human-generated light detection. We utilize the regional light
characteristics in the filtering process in two ways. First, we include
more regional variables as inputs in the random forest algorithm.
Second, \\
we divide the world into sub-regions and run the algorithm separately
for each region. This allows \\
the algorithm to learn how the light characteristics relate to built-up
areas in different sub-regions. \\
Since that relationship most likely differs across the world, we achieve
a better prediction accuracy by \\
allowing for variations in the classification rule. \\
In practice, we crop the variable images into 2000 × 2000 pixel
sub-regions after the data preparation \\
phase (Step 1). Accordingly, the size of a sub-region is approximately
3.4 million km2 at the equator, \\
which is close to the size of India. The number of rows in a sub-region
is 4 million, and we take a \\
subsample of 10\% for the model training. By running different versions,
we found this window size to \\
have a good balance between improvements in prediction accuracy and
being widely independent of \\
the quality of the built-up data. However, the changes in the
classification rule across the sub-regions \\
causes a problem at their borders. The shifts in predicted
probabilities, and consequently the number \\
of lit pixels, are visibly clear. \\
The solution for smoothing the border effects is to move the sub-region
window in smaller steps \\
and then average the results. The step size should be as small as
possible, but we rapidly run into \\
computational constraints. Therefore, we decide to move the window in
steps of 250 pixels so that we \\
receive 64 values for each pixel. Unlike in the global approach, we now
set the number of lit pixels \\
within each window by using a 4\% tolerance level. This means that we
keep classifying light in pixels \\
as human-generated in the order of highest probability until 4\% of
avg\_light pixels with values below 5 \\
are included. By setting the amount of light with this tolerance
threshold, we avoid having to make \\
subjective choices of light amounts across regions or base them on the
built-up data. However, we have \\
to include a backstop or we end up adding lit pixels also in areas where
there is no human-generated \\
light at all. Therefore, we additionally set all pixels with a predicted
probability less than 20\% of being \\
human-generated to zero. \\
As described above, we classify light in each pixel 64 times by the
overlapping sub-region windows \\
as human-generated or not. After Step 3 in the filtering process, we
mosaic all the windows and \\
count the classifications. We then create the final product in Step 4 by
taking the light value from the \\
average visible band image if a pixel is classified as human-generated
more than eight times out of \\
64. Otherwise, we set the light value in a pixel to zero. The
requirement of eight human-generated \\
light classifications makes a final global adjustment to the amount of
light. We have chosen the light \\
amount settings in a way that balances the improvement in detecting
human-generated light while \\
keeping misclassifications at a low level. Howeve \\
\bottomrule
\end{longtable}

Although our methodology largely follows that presented by Määttä \&
Lessmann (\protect\hyperlink{ref-maatta}{2019}), there are some distinct
differences.

\begin{itemize}
\tightlist
\item
  Size of area
\item
  Jitter size
\item
  Probability of human-generated
\item
  only f152001, we do f142001 and f182011 as well
\end{itemize}

\hypertarget{random-forest-algorithm}{%
\subsection{Random Forest Algorithm}\label{random-forest-algorithm}}

RF

\hypertarget{results}{%
\section{\texorpdfstring{Results
\label{Results}}{Results }}\label{results}}

\begin{itemize}
\tightlist
\item
  maps comparing stable lights with noise removed vs human-generated
  light (overlay map)
\item
  also amount/percentage of pixels saved
\item
  accuracy measures?
\end{itemize}

\hypertarget{discussion}{%
\section{\texorpdfstring{Discussion
\label{Discussion}}{Discussion }}\label{discussion}}

This paper extended the usage of a filtering methodology proposed by
Määttä \& Lessmann (\protect\hyperlink{ref-maatta}{2019}) with which to
separate background noise from human-generated nightlight data.

Our results echo those by Määttä \& Lessmann
(\protect\hyperlink{ref-maatta}{2019}): the RF algorithm introduces
great improvements in classification accuracy and thus greater accuracy
in filtering out background noise from the `Stable Lights' product. This
allows the researcher to do away with the need for quick-and-easy type
fixes to noisy data at the lower end of the luminosity distribution.

However, it is important to note what this method does not achieve. For
instance, the `Human Lights' product does not address the issue of
blooming or oversaturation at the high end of the luminosity spectrum.
Likewise, its spatial resolution remains low in comparison to more
modern products such as the Visible Infrared Imaging Radiometer Suite
(VIIRS), and it is recommended to use these products rather than the
DMSP-OLS `Stable Lights' or `Human Lights' products if possible.

\newpage

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-maatta}{}}%
Määttä, I. \& Lessmann, C. 2019. Human lights. \emph{Remote Sensing}.
11(19):2194.

\end{CSLReferences}

\hypertarget{appendix}{%
\section*{Appendix}\label{appendix}}
\addcontentsline{toc}{section}{Appendix}

\begin{itemize}
\tightlist
\item
  images of all the different local images - refer them back to
  variables table
\end{itemize}

plot of initial stable lights product

plot of stable lights product with noise filtered out at lower end

plot of noise-filtered result

overlay plot of the above two with different colours

\bibliography{Tex/ref}





\end{document}
